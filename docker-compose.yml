services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "7000:7000"
    environment:
      - MONGO_URL=${MONGO_URL}

  triton-server:
      image: nvcr.io/nvidia/tritonserver:23.10-py3
      ports:
        - "8000:8000"
      volumes:
        - ./model_repository:/models
      environment:
        - CUDA_VISIBLE_DEVICES=-1
        - FORCE_CPU=1
      command: tritonserver --model-repository=/models --backend-config=pytorch,execution_accelerator=cpu
